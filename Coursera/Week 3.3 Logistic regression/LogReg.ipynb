{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('C:/Users/1/Data/LogReg/data-logistic.csv', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.663827</td>\n",
       "      <td>-0.138526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.994596</td>\n",
       "      <td>2.468025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.247395</td>\n",
       "      <td>0.749425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2.309374</td>\n",
       "      <td>1.899836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.849143</td>\n",
       "      <td>2.407750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0         1         2\n",
       "0 -1 -0.663827 -0.138526\n",
       "1  1  1.994596  2.468025\n",
       "2 -1 -1.247395  0.749425\n",
       "3  1  2.309374  1.899836\n",
       "4  1  0.849143  2.407750"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(205, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data.iloc[:, [1, 2]].values\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(205,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = data[0].values\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogReg:\n",
    "    \n",
    "    def __init__(self, C = 0, k = 0.1, min_change = 10**-5, n_iter = 10000):\n",
    "        self.C = C # коэффициент регуляризации\n",
    "        self.k = k # длина градиентного шага   \n",
    "        self.min_change = min_change # величина минимального изменения весов\n",
    "        self.n_iter = n_iter # количество итераций обучения\n",
    "    \n",
    "    def fit(self, X, Y):\n",
    "        self.lenth = X.shape[0] # количество объектов обучающей выборки\n",
    "        self.weights = np.zeros(X.shape[1]) # инициализация весов (на старте веса нулевые)\n",
    "        \n",
    "        for step in range(self.n_iter): \n",
    "            prev_weights = np.copy(self.weights) # веса на предыдущей итерации\n",
    "            \n",
    "            Margin = X.dot(self.weights) * Y # рассчитываем отступ \n",
    "            prob = self.sigmoid(Margin) # рассчитываем апостериорную вероятность принадлежности к классу\n",
    "\n",
    "            grad = self.gradient(X, Y, prob) # рассчитываем градиент\n",
    "                     \n",
    "            weight_delta = self.k * grad\n",
    "            self.weights -= weight_delta # обновляем веса\n",
    "            \n",
    "            # проверяем евклидово расстояние между векторами весов на соседних итерациях\n",
    "            dist = np.sqrt(np.sum(np.square(self.weights - prev_weights)))\n",
    "            if dist <= self.min_change:\n",
    "                print(f'Алгоритм сошелся на {step} итерации')\n",
    "                break\n",
    "            \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        dot_prod = X.dot(self.weights)\n",
    "        pred = self.sigmoid(dot_prod)\n",
    "        return pred\n",
    "        \n",
    "    def sigmoid(self, dot_prod):\n",
    "        return 1 / (1 + np.exp(-dot_prod))\n",
    "    \n",
    "    def gradient(self, X, Y, prob):\n",
    "        grad = np.zeros(X.shape[1])\n",
    "        for i in range(X.shape[1]):\n",
    "            grad[i] = - np.sum(Y * X[:, i] * (1 - prob)) / self.lenth + self.C * self.weights[i]\n",
    "        return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Алгоритм сошелся на 243 итерации\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.44922586, 0.69020649, 0.42798423, 0.6983426 , 0.61440485,\n",
       "       0.58839854, 0.70203837, 0.52888936, 0.41971211, 0.59584612,\n",
       "       0.4997746 , 0.49906568, 0.47920412, 0.59768339, 0.64958906,\n",
       "       0.5687875 , 0.47086925, 0.62138228, 0.66983526, 0.74475216,\n",
       "       0.54577233, 0.01543129, 0.41544251, 0.44921358, 0.61272547,\n",
       "       0.53710786, 0.69773006, 0.75864364, 0.47126841, 0.58722554,\n",
       "       0.46196938, 0.48523066, 0.78569546, 0.7499381 , 0.51786719,\n",
       "       0.660825  , 0.70493808, 0.66732057, 0.58362091, 0.69606071,\n",
       "       0.64785173, 0.44015592, 0.59468979, 0.46013921, 0.53033774,\n",
       "       0.64207864, 0.8042442 , 0.47228757, 0.55307849, 0.55490638,\n",
       "       0.65095744, 0.58562266, 0.57476233, 0.70849238, 0.43468645,\n",
       "       0.4709801 , 0.50374559, 0.70893964, 0.57090302, 0.70239483,\n",
       "       0.6692237 , 0.65309035, 0.6969174 , 0.7260847 , 0.53189639,\n",
       "       0.64652243, 0.53656743, 0.00550396, 0.56367596, 0.66559481,\n",
       "       0.64259021, 0.51360061, 0.75324991, 0.45684737, 0.43295614,\n",
       "       0.44359186, 0.70726892, 0.62799966, 0.70131187, 0.55985197,\n",
       "       0.73666748, 0.39067693, 0.68759455, 0.66269438, 0.58349537,\n",
       "       0.75924054, 0.55591254, 0.49029183, 0.52479209, 0.51556589,\n",
       "       0.59804953, 0.49902176, 0.67165375, 0.54974165, 0.44045104,\n",
       "       0.62456068, 0.62412022, 0.44620762, 0.45055809, 0.63147914,\n",
       "       0.69306009, 0.60124912, 0.44463152, 0.56400438, 0.46500615,\n",
       "       0.52524378, 0.6376163 , 0.72119828, 0.63365612, 0.47820626,\n",
       "       0.41672598, 0.70652873, 0.66486219, 0.59021274, 0.62261705,\n",
       "       0.03505133, 0.50225939, 0.53665176, 0.72647402, 0.44294758,\n",
       "       0.76279779, 0.50819504, 0.63811069, 0.39572179, 0.70370146,\n",
       "       0.68997539, 0.77021063, 0.53633865, 0.66153424, 0.00478253,\n",
       "       0.67762172, 0.6107163 , 0.4942067 , 0.56203794, 0.78279909,\n",
       "       0.41377636, 0.73418341, 0.58015417, 0.80082776, 0.54431682,\n",
       "       0.6886865 , 0.68033933, 0.66356798, 0.58463608, 0.67249992,\n",
       "       0.70414746, 0.62535601, 0.6032523 , 0.70716174, 0.70226605,\n",
       "       0.47176869, 0.45574298, 0.5803882 , 0.38065261, 0.71974417,\n",
       "       0.36605398, 0.39951847, 0.72846855, 0.49665253, 0.47738597,\n",
       "       0.43396505, 0.40034293, 0.64996367, 0.62830056, 0.67329447,\n",
       "       0.69041285, 0.50795041, 0.61450777, 0.57600612, 0.38357811,\n",
       "       0.68925442, 0.54246548, 0.61072858, 0.4588988 , 0.68484307,\n",
       "       0.57676706, 0.51410891, 0.66244651, 0.50252592, 0.7277038 ,\n",
       "       0.70737497, 0.51416605, 0.69799807, 0.5230048 , 0.60804459,\n",
       "       0.5061852 , 0.61616393, 0.44945572, 0.49542905, 0.43996772,\n",
       "       0.80018845, 0.71777938, 0.50479292, 0.42063536, 0.64592267,\n",
       "       0.70658673, 0.5251899 , 0.70260937, 0.73231059, 0.42285293,\n",
       "       0.81798006, 0.69562738, 0.40153552, 0.03747559, 0.52001394])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogReg()\n",
    "clf.fit(X, Y)\n",
    "pred = clf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_true = list(map(lambda y: 0 if y < 0 else 1 , Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.927"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(roc_auc_score(Y_true, pred), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Алгоритм сошелся на 7 итерации\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.49440255, 0.529496  , 0.4957368 , 0.52822771, 0.52096641,\n",
       "       0.50626044, 0.53008234, 0.50861803, 0.48873776, 0.51757601,\n",
       "       0.50191648, 0.50154946, 0.49341161, 0.50558998, 0.52228362,\n",
       "       0.50434259, 0.4929596 , 0.5191125 , 0.52195573, 0.53489214,\n",
       "       0.50218015, 0.38131965, 0.48731919, 0.49206967, 0.51203573,\n",
       "       0.50395002, 0.53069129, 0.54107763, 0.49839379, 0.5135726 ,\n",
       "       0.4945121 , 0.50247534, 0.54600482, 0.53262053, 0.5073897 ,\n",
       "       0.51378546, 0.53417603, 0.52300976, 0.50720322, 0.52383035,\n",
       "       0.51828015, 0.49704681, 0.51270112, 0.49238438, 0.50703299,\n",
       "       0.51972797, 0.54388304, 0.49726854, 0.50568197, 0.51436456,\n",
       "       0.51874495, 0.52003243, 0.50555806, 0.53033633, 0.48905037,\n",
       "       0.50576537, 0.50555325, 0.53182041, 0.50860904, 0.53190478,\n",
       "       0.52459388, 0.51539334, 0.52853379, 0.53113754, 0.50373856,\n",
       "       0.52590253, 0.5046051 , 0.31746315, 0.50827102, 0.53065557,\n",
       "       0.51182656, 0.50893571, 0.54016531, 0.49300493, 0.4895921 ,\n",
       "       0.49723045, 0.52779637, 0.51188452, 0.53160048, 0.51094066,\n",
       "       0.53580939, 0.48805334, 0.52509998, 0.52491486, 0.51028473,\n",
       "       0.54169431, 0.51209297, 0.50398705, 0.505466  , 0.49419259,\n",
       "       0.51290447, 0.49292843, 0.52568309, 0.50581195, 0.49214557,\n",
       "       0.52391321, 0.51261368, 0.49923978, 0.49348156, 0.52066488,\n",
       "       0.52748202, 0.51623289, 0.49529369, 0.50557622, 0.48666221,\n",
       "       0.50751567, 0.51856927, 0.53593917, 0.52326137, 0.49713001,\n",
       "       0.48826019, 0.53404211, 0.52594283, 0.51972217, 0.5148997 ,\n",
       "       0.39313839, 0.50599441, 0.50108051, 0.52970813, 0.49391298,\n",
       "       0.53402357, 0.50358699, 0.52393739, 0.49277362, 0.5325404 ,\n",
       "       0.52541122, 0.53785005, 0.51303954, 0.52468871, 0.30866359,\n",
       "       0.52651123, 0.51452067, 0.49539778, 0.50162987, 0.54321196,\n",
       "       0.488474  , 0.54165212, 0.51113034, 0.54350816, 0.50469213,\n",
       "       0.53382236, 0.52936625, 0.52789474, 0.51113027, 0.51764619,\n",
       "       0.52848547, 0.51896231, 0.51366213, 0.5272887 , 0.5373611 ,\n",
       "       0.50083726, 0.49279272, 0.51443224, 0.49022477, 0.53104778,\n",
       "       0.48775333, 0.48419575, 0.52772716, 0.50543195, 0.49808911,\n",
       "       0.48687743, 0.48371985, 0.52386725, 0.52115083, 0.52681928,\n",
       "       0.53259819, 0.49511943, 0.51446465, 0.50716617, 0.48494706,\n",
       "       0.5334962 , 0.5027807 , 0.51323583, 0.49318538, 0.52390694,\n",
       "       0.51823961, 0.50673172, 0.5230015 , 0.4972823 , 0.53447902,\n",
       "       0.53462882, 0.50636939, 0.52639449, 0.49731474, 0.51671462,\n",
       "       0.49774497, 0.50568832, 0.49812898, 0.50373251, 0.49035512,\n",
       "       0.53868526, 0.52299439, 0.50584171, 0.48733167, 0.51393913,\n",
       "       0.53285803, 0.49870701, 0.52957243, 0.53087315, 0.49170669,\n",
       "       0.54906999, 0.52579482, 0.49610092, 0.36814354, 0.5053723 ])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2 = LogReg(C=10)\n",
    "clf2.fit(X, Y)\n",
    "pred2 = clf2.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.936"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(roc_auc_score(Y_true, pred2), 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
